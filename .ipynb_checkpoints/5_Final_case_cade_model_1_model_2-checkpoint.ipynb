{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1eec7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import Field,TabularDataset,BucketIterator,Iterator\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b0f947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check for CUDA\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad1352ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "test_model1 = pd.read_csv('splited_data/test_m1.csv')\n",
    "test_model2 = pd.read_csv('splited_data/test_m2.csv')\n",
    "test_cascade = pd.read_csv('splited_data/test3.csv') # this data will be used for both testing base line model and cas cade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fc3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cbc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolationBert(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ViolationBert,self).__init__()\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def forward(self,text,label):\n",
    "        loss,text_features = self.encoder(text,labels = label)[:2]\n",
    "        return loss, text_features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5437d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(load_path,model):\n",
    "    state_dict = torch.load(load_path,map_location= device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b257d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max sequence lentgh\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36939fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence prediction fucntion using trained model\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode_plus(sentence, max_length=MAX_SEQ_LENGTH, truncation=True, padding='max_length', add_special_tokens=True, return_token_type_ids=False, return_attention_mask=True, return_tensors='pt').to(device)\n",
    "    labels = torch.tensor(0).unsqueeze(0).to(device)\n",
    "    outputs = model(tokens['input_ids'], labels)\n",
    "    _, predicted = torch.max(outputs[1], 1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfce430",
   "metadata": {},
   "source": [
    "### Model1 perforance of normal and hate/offensive class detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7c9229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== model/model1.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23836193405091763"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model and Evaluate\n",
    "model1= ViolationBert().to(device)\n",
    "#your checkpoint location\n",
    "load_checkpoint('model/model1.pt',model1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e62cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "predictions=[]\n",
    "for post in test_model1['review'][:100]:\n",
    "    predictions.append(predict_sentiment(model1, post))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33ff3dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model1: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.955     0.875     0.913        72\n",
      "           0      0.735     0.893     0.806        28\n",
      "\n",
      "    accuracy                          0.880       100\n",
      "   macro avg      0.845     0.884     0.860       100\n",
      "weighted avg      0.893     0.880     0.883       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy calculation     \n",
    "accuracy = metrics.classification_report(np.array(predictions),np.array(test_model1['label'][:100]), labels=[1,0], digits=3)\n",
    "print('Accuracy of model1: \\n')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e6411",
   "metadata": {},
   "source": [
    "### Model2 performance of  hate and offensive class detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16cfd600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== model/model2.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.631134359609513"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model and Evaluate\n",
    "model2= ViolationBert().to(device)\n",
    "#your checkpoint location\n",
    "load_checkpoint('model/model2.pt',model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcd9b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "predictions=[]\n",
    "for post in test_model2['review'][:100]:\n",
    "    predictions.append(predict_sentiment(model2, post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48601462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model2: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.683     0.636     0.659        44\n",
      "           1      0.729     0.768     0.748        56\n",
      "\n",
      "    accuracy                          0.710       100\n",
      "   macro avg      0.706     0.702     0.703       100\n",
      "weighted avg      0.709     0.710     0.709       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy calculation     \n",
    "accuracy = metrics.classification_report(np.array(predictions),np.array(test_model2['label'][:100]),  digits=3)\n",
    "print('Accuracy of model2: \\n')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "035418a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>treason lots of u up that way canada has the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>catch woahs and pull hoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>it would be nice to see that judge get raped a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the jewish question is probably the greatest l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>that white devil that killed the black man hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>getting non muslims to pronounce my name corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>gets arrested for saying nigger civic national...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2</td>\n",
       "      <td>yeah that one was special he got really mad at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>r u kidding it be all over the news lol media ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is white trash it embarrassing that anyo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         1  treason lots of u up that way canada has the l...\n",
       "1         0                          catch woahs and pull hoes\n",
       "2         1  it would be nice to see that judge get raped a...\n",
       "3         0  the jewish question is probably the greatest l...\n",
       "4         2  that white devil that killed the black man hon...\n",
       "...     ...                                                ...\n",
       "1995      0  getting non muslims to pronounce my name corre...\n",
       "1996      0  gets arrested for saying nigger civic national...\n",
       "1997      2  yeah that one was special he got really mad at...\n",
       "1998      0  r u kidding it be all over the news lol media ...\n",
       "1999      0  trump is white trash it embarrassing that anyo...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40663c",
   "metadata": {},
   "source": [
    "### Cascading both model1 and model 2 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5c96013",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for post in test_cascade['review'][:100]:\n",
    "    result1=predict_sentiment(model1, post)\n",
    "    if result1==0:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        result2=predict_sentiment(model2, post)\n",
    "        if result2==0:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "885b2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model1: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.860     0.925     0.892        40\n",
      "           1      0.833     0.758     0.794        33\n",
      "           2      0.667     0.667     0.667        27\n",
      "\n",
      "    accuracy                          0.800       100\n",
      "   macro avg      0.787     0.783     0.784       100\n",
      "weighted avg      0.799     0.800     0.799       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy calculation     \n",
    "accuracy = metrics.classification_report(np.array(predictions),np.array(test_cascade['label'][:100]),  digits=3)\n",
    "print('Accuracy of model1: \\n')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f9f83da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(np.array(predictions),np.array(test_cascade['label'][:100]))\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Normal', 'hate','offensive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
