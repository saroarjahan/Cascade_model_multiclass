{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"D9AkPPdzzUcn"},"outputs":[],"source":["import transformers\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModel\n","import torch\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54lUo7Z-zUcu"},"outputs":[],"source":["from transformers import MarianMTModel, MarianTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-IwobrWwzUc1","outputId":"4b33e62e-a0a1-4635-ddb0-dece703b3f2e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>let me go to bed nazi faggot maybe i can catch...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>making fun of retarded kids is bad but using t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>i bet this negroid is in ghetto hell wishing h...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>btw it awesome that we can repost comments aga...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>curanis are nigger jews</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>931</th>\n","      <td>1</td>\n","      <td>if ur still on twitter tell carlton i said his...</td>\n","    </tr>\n","    <tr>\n","      <th>932</th>\n","      <td>1</td>\n","      <td>when i first got on here and said i hate trump...</td>\n","    </tr>\n","    <tr>\n","      <th>933</th>\n","      <td>1</td>\n","      <td>was macht der moslem wenn der zion gegen seine...</td>\n","    </tr>\n","    <tr>\n","      <th>934</th>\n","      <td>0</td>\n","      <td>it is awful look at world demographics asians ...</td>\n","    </tr>\n","    <tr>\n","      <th>935</th>\n","      <td>0</td>\n","      <td>the jewish globalist elite have only imported ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>936 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["     label                                             review\n","0        1  let me go to bed nazi faggot maybe i can catch...\n","1        1  making fun of retarded kids is bad but using t...\n","2        0  i bet this negroid is in ghetto hell wishing h...\n","3        1  btw it awesome that we can repost comments aga...\n","4        0                            curanis are nigger jews\n","..     ...                                                ...\n","931      1  if ur still on twitter tell carlton i said his...\n","932      1  when i first got on here and said i hate trump...\n","933      1  was macht der moslem wenn der zion gegen seine...\n","934      0  it is awful look at world demographics asians ...\n","935      0  the jewish globalist elite have only imported ...\n","\n","[936 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data= pd.read_csv('train_m2.csv')\n","data"]},{"cell_type":"code","source":["#refernce code from hugging face\n","model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)\n","\n","english_model = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n","english_tokenizer = MarianTokenizer.from_pretrained(english_model)\n","english_model = MarianMTModel.from_pretrained(english_model)\n","\n","def translate(texts, model, tokenizer, language=\"fr\"):\n","    # Prepare the text data into appropriate format for the model\n","    template = lambda text: f\"{text}\" if language == \"en\" else f\">>{language}<< {text}\"\n","    src_texts = [template(text) for text in texts]\n","\n","    # Tokenize the texts\n","    encoded = tokenizer.prepare_seq2seq_batch(src_texts, return_tensors='pt')\n","    \n","    # Generate translation using model\n","    translated = model.generate(**encoded)\n","\n","    # Convert the generated tokens indices back into text\n","    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n","    \n","    return translated_texts\n","\n","def back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n","    \n","    # Translate from source to target language\n","    fr_texts = translate(texts, model, tokenizer, language=target_lang)\n","\n","    # Translate from target language back to source language\n","    back_translated_texts = translate(fr_texts, english_model, english_tokenizer, language=source_lang)\n","    \n","    return back_translated_texts"],"metadata":{"id":"rMpc0c9YH2wh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlBKEBQFzUc3"},"outputs":[],"source":["def back(text):\n","    en_texts = [text]\n","    aug1 = back_translate(en_texts, source_lang=\"en\", target_lang=\"es\")\n","    aug2 = back_translate(en_texts, source_lang=\"en\", target_lang=\"fr\")\n","    aug=[aug1[0],aug2[0]]\n","    aug=list(dict.fromkeys(aug))\n","    return aug\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOzHzDr8zUc5"},"outputs":[],"source":["aug_qa=[]\n","new_label=[]\n","ori_qa=[]\n","for i in  range(935): \n","    aug_text = back(data['review'][i])\n","    for j in aug_text:\n","        if j != data['review'][i]:\n","            aug_qa.append(j)\n","            new_label.append(data['label'][i])\n","            ori_qa.append(data['review'][i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnIOoIB0zUc6"},"outputs":[],"source":["print(len(ori_qa))\n","print(len(aug_qa))\n","print(len(new_label))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmtZqvdqzUc7"},"outputs":[],"source":["my_dict = { 'label':new_label, 'review':aug_qa,}\n","df = pd.DataFrame(my_dict)\n","df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JwnvilFzUc9"},"outputs":[],"source":["result = pd.concat([data,df],ignore_index=True)\n","result.to_csv('augment_test_m2.csv',index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}